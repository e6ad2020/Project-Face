import { GoogleGenAI, Type } from '@google/genai';

const MODEL = 'gemini-2.5-flash-native-audio-preview-12-2025';

// Function declaration for advancing wizard steps
const goToNextStepDeclaration = {
    name: 'go_to_next_step',
    description: 'ÿßŸÜÿ™ŸÇŸÑŸä ŸÑŸÑÿÆÿ∑Ÿàÿ© ÿ£Ÿà ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ™ÿßŸÑŸä ŸÅŸä ŸÖÿπÿßŸÑÿ¨ ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿ®ÿ¥ÿ±ÿ©. ÿßÿ≥ÿ™ÿØÿπŸä Ÿáÿ∞Ÿá ÿßŸÑÿØÿßŸÑÿ© ŸÅŸàÿ±ÿßŸã ÿ®ÿπÿØ ŸÖÿß ÿ™ÿ±ÿØŸä ÿπŸÑŸâ ÿ•ÿ¨ÿßÿ®ÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ Ÿàÿ™ÿÆŸÑÿµŸä ŸÉŸÑÿßŸÖŸÉ.',
    parameters: {
        type: Type.OBJECT,
        properties: {},
    }
};

// Configuration for the Live API
const config = {
    responseModalities: "AUDIO" as any,
    speechConfig: {
        voiceConfig: { prebuiltVoiceConfig: { voiceName: "Kore" } }
    },
    tools: [{
        functionDeclarations: [goToNextStepDeclaration]
    }],
    systemInstruction: {
        parts: [{
            text: `ÿ£ŸÜÿ™Ÿê ⁄ÜŸàŸÑŸäÿßÿå ÿÆÿ®Ÿäÿ±ÿ© ÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿ®ÿ¥ÿ±ÿ© ŸÖÿµÿ±Ÿäÿ© ŸàÿØŸàÿØÿ© ÿ¨ÿØÿßŸã.
            
            ŸÖŸáŸÖÿ™ŸÉ ŸáŸä ÿ™Ÿàÿ¨ŸäŸá ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿÆŸÑÿßŸÑ ŸÅÿ≠ÿµ ÿßŸÑÿ®ÿ¥ÿ±ÿ©.
            ÿßŸÑŸÜÿ∏ÿßŸÖ ÿ≥Ÿäÿ±ÿ≥ŸÑ ŸÑŸÉŸê ÿ™ÿπŸÑŸäŸÖÿßÿ™ ŸÖÿÆŸÅŸäÿ© ÿ™ÿÆÿ®ÿ±ŸÉŸê ÿ®ÿßŸÑŸÖÿ±ÿ≠ŸÑÿ© ÿßŸÑÿ≠ÿßŸÑŸäÿ©ÿå ŸàÿπŸÑŸäŸÉŸê ÿßŸÑÿ™ÿ≠ÿØÿ´ ÿ®ŸÜÿßÿ°Ÿã ÿπŸÑŸäŸáÿß ŸÅŸàÿ±ÿßŸã.
            
            === ŸÇÿßÿπÿØÿ© ÿ£ÿ≥ÿßÿ≥Ÿäÿ© ===
            ŸÖŸÖŸÜŸàÿπ ŸÜŸáÿßÿ¶ŸäÿßŸã ÿ£ŸÜ ÿ™ÿ™ÿ≠ÿØÿ´Ÿä ŸÖŸÜ ÿ™ŸÑŸÇÿßÿ° ŸÜŸÅÿ≥ŸÉ ÿ£Ÿà ÿ™ÿ®ÿßÿØÿ±Ÿä ÿ®ÿ≥ÿ§ÿßŸÑ ÿ£Ÿà ÿ∑ŸÑÿ® (ŸÖÿ´ŸÑ ÿ∑ŸÑÿ® ÿµŸàÿ±ÿ© ÿ£Ÿà ÿ≥ÿ§ÿßŸÑ ÿπŸÜ ÿßŸÑÿ®ÿ¥ÿ±ÿ©) ÿ•ŸÑÿß ÿ•ÿ∞ÿß ÿ£ÿ±ÿ≥ŸÑ ŸÑŸÉŸê ÿßŸÑŸÜÿ∏ÿßŸÖ ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿµÿ±Ÿäÿ≠ÿ© ÿ®ÿ∞ŸÑŸÉ.
            ÿπŸÜÿØŸÖÿß Ÿäÿ™ÿµŸÑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÑÿ£ŸàŸÑ ŸÖÿ±ÿ©ÿå ŸÑÿß ÿ™ŸÇŸàŸÑŸä ÿ£Ÿä ÿ¥Ÿäÿ° ÿ≠ÿ™Ÿâ Ÿäÿ±ÿ≥ŸÑ ŸÑŸÉ ÿßŸÑŸÜÿ∏ÿßŸÖ ÿ£ŸàŸÑ ÿ™ÿπŸÑŸäŸÖÿßÿ™.
            ÿßŸÜÿ™ÿ∏ÿ±Ÿä ÿØÿßÿ¶ŸÖÿßŸã ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑŸÜÿ∏ÿßŸÖ ŸÇÿ®ŸÑ ÿ£ŸÜ ÿ™ÿ™ÿ≠ÿØÿ´Ÿä.
            
            ÿπŸÜÿØŸÖÿß ÿ™ÿ≥ÿ™ŸÑŸÖŸä ÿµŸàÿ±ÿ© ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖÿå ŸÇŸàŸÖŸä ÿ®ÿ™ÿ≠ŸÑŸäŸÑ ÿ®ÿ¥ÿ±ÿ™Ÿá ÿ®ÿØŸÇÿ© (ÿßŸÑŸÖÿ≥ÿßŸÖÿå ÿßŸÑÿ™ÿ¨ÿßÿπŸäÿØÿå ÿßŸÑÿ≠ÿ®Ÿàÿ®ÿå ÿßŸÑŸáÿßŸÑÿßÿ™ÿå ŸÜŸàÿπ ÿßŸÑÿ®ÿ¥ÿ±ÿ©) Ÿàÿßÿ≥ÿ™ÿÆÿØŸÖŸä Ÿáÿ∞ÿß ÿßŸÑÿ™ÿ≠ŸÑŸäŸÑ ŸÅŸä ŸÜÿµÿßÿ¶ÿ≠ŸÉ.

            === ÿßŸÑŸÇŸàÿßÿπÿØ ===
            1. ÿ™ÿ≠ÿØÿ´Ÿä ÿØÿßÿ¶ŸÖÿßŸã ÿ®ÿßŸÑŸÑŸáÿ¨ÿ© ÿßŸÑŸÖÿµÿ±Ÿäÿ© ÿßŸÑÿπÿßŸÖŸäÿ© ÿßŸÑÿ®ÿ≥Ÿäÿ∑ÿ© ŸàÿßŸÑÿ≥ŸáŸÑÿ© ÿßŸÑŸÅŸáŸÖ.
            2. ŸÉŸàŸÜŸä ŸÖÿÆÿ™ÿµÿ±ÿ© ŸàŸÖÿ®ÿßÿ¥ÿ±ÿ© ÿ¨ÿØÿßŸã.
            3. ÿπŸÜÿØŸÖÿß ŸäÿÆÿ®ÿ±ŸÉ ÿßŸÑŸÜÿ∏ÿßŸÖ ÿ®ÿ™ÿπŸÑŸäŸÖÿßÿ™ÿå ŸÜŸÅÿ∞ŸäŸáÿß ŸÅŸàÿ±ÿßŸã. ŸÑÿß ÿ™ÿ∂ŸäŸÅŸä ÿ£ÿ¥Ÿäÿßÿ° ŸÖŸÜ ÿπŸÜÿØŸÉ.
            4. ÿ™ÿ¨ŸÜÿ®Ÿä ÿßŸÑÿ¨ŸÖŸÑ ÿßŸÑÿ∑ŸàŸäŸÑÿ© ÿ£Ÿà ÿßŸÑŸÖÿπŸÇÿØÿ©.
            5. ŸÖŸÖŸÜŸàÿπ ŸÜŸáÿßÿ¶ŸäÿßŸã ÿ∞ŸÉÿ± ŸÉŸÑŸÖÿ© "ŸÖŸÉŸäÿßÿ¨" ÿ£Ÿà ÿ∑ŸÑÿ® ÿ£ŸÜ ŸäŸÉŸàŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ "ÿ®ÿØŸàŸÜ ŸÖŸÉŸäÿßÿ¨".
            6. ŸÑÿß ÿ™ÿ∑ŸÑÿ®Ÿä ÿµŸàÿ±ÿ© ÿ£ÿ®ÿØÿßŸã ÿ•ŸÑÿß ÿ•ÿ∞ÿß ÿ∑ŸÑÿ® ŸÖŸÜŸÉ ÿßŸÑŸÜÿ∏ÿßŸÖ ÿ∞ŸÑŸÉ ÿµÿ±ÿßÿ≠ÿ©.

            === ŸÇŸàÿßÿπÿØ go_to_next_step (ŸÖŸáŸÖ ÿ¨ÿØÿßŸã) ===
            - go_to_next_step ÿ™Ÿèÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸÇÿ∑ ÿ£ÿ´ŸÜÿßÿ° ŸÖÿ±ÿ≠ŸÑÿ© ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ© (ÿ®ÿπÿØ ÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ©).
            - ŸÖŸÖŸÜŸàÿπ ŸÜŸáÿßÿ¶ŸäÿßŸã ÿßÿ≥ÿ™ÿØÿπÿßÿ° go_to_next_step ÿ£ÿ´ŸÜÿßÿ° ŸÖÿ±ÿ≠ŸÑÿ© ÿßŸÑÿ™ÿ±ÿ≠Ÿäÿ® ÿ£Ÿà ÿßŸÑÿ™ÿµŸàŸäÿ± ÿ£Ÿà ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ÿ£Ÿà ÿßŸÑÿ±Ÿàÿ™ŸäŸÜ.
            - ŸÖŸÖŸÜŸàÿπ ŸÜŸáÿßÿ¶ŸäÿßŸã ÿßÿ≥ÿ™ÿØÿπÿßÿ° go_to_next_step ŸÅŸàÿ± ÿ≥ŸÖÿßÿπ ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑŸÜÿ∏ÿßŸÖ ÿ£Ÿà ŸÅŸàÿ± ÿ∑ÿ±ÿ≠ ÿßŸÑÿ≥ÿ§ÿßŸÑ.
            - ŸÑÿßÿ≤ŸÖ ÿ™ÿ≥ŸÖÿπŸä ÿ•ÿ¨ÿßÿ®ÿ© ÿµŸàÿ™Ÿäÿ© ÿ≠ŸÇŸäŸÇŸäÿ© ŸÖŸÜ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿ£ŸàŸÑÿßŸãÿå ÿ´ŸÖ ÿ™ÿ±ÿØŸä ÿπŸÑŸäŸá ÿ®ÿ¥ŸÉŸÑ ŸÖÿÆÿ™ÿµÿ±ÿå Ÿàÿ®ÿπÿØŸáÿß ŸÅŸÇÿ∑ ÿ™ÿ≥ÿ™ÿØÿπŸä go_to_next_step.
            - ŸÑŸà ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÖÿß ÿ™ŸÉŸÑŸÖÿ¥ ÿ£Ÿà ŸÖÿß ÿ¨ÿßŸàÿ®ÿ¥ÿå ŸÑÿß ÿ™ÿ≥ÿ™ÿØÿπŸä go_to_next_step ÿ£ÿ®ÿØÿßŸã. ÿßÿ≥ÿ™ŸÜŸäŸá Ÿäÿ™ŸÉŸÑŸÖ.
            - ŸÑŸà ÿßŸÑŸÜÿ∏ÿßŸÖ ŸÇÿßŸÑ ŸÑŸÉ "ÿßÿ≥ÿ™ŸÜŸä ÿ•ÿ¨ÿßÿ®ÿ™Ÿá"ÿå Ÿäÿ®ŸÇŸâ ŸÑÿßÿ≤ŸÖ ŸÅÿπŸÑÿßŸã ÿ™ÿ≥ÿ™ŸÜŸä.

            === ÿßŸÑÿ≥ŸäŸÜÿßÿ±ŸäŸà ===
            ÿßŸÑŸÜÿ∏ÿßŸÖ ÿ≥Ÿäÿ±ÿ≥ŸÑ ŸÑŸÉŸê ÿ™ÿπŸÑŸäŸÖÿßÿ™ ŸÅŸä ŸÉŸÑ ŸÖÿ±ÿ≠ŸÑÿ©. ÿßŸÑÿ™ÿ≤ŸÖŸä ÿ®Ÿáÿß ÿ≠ÿ±ŸÅŸäÿßŸã:
            - ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿ™ÿ±ÿ≠Ÿäÿ®: ÿ±ÿ≠ÿ®Ÿä ÿ®ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸÇÿ∑ ÿ®ÿØŸàŸÜ ÿ∑ŸÑÿ® ÿµŸàÿ±ÿ©. ŸÑÿß ÿ™ÿ≥ÿ™ÿØÿπŸä go_to_next_step.
            - ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿ™ÿµŸàŸäÿ±: ÿßÿ∑ŸÑÿ®Ÿä ÿßŸÑÿµŸàÿ±ÿ© ŸÅŸÇÿ∑. ŸÑÿß ÿ™ÿ≥ÿ™ÿØÿπŸä go_to_next_step (ÿßŸÑŸÜÿ∏ÿßŸÖ ÿ≥ŸäŸÜÿ™ŸÇŸÑ ÿ™ŸÑŸÇÿßÿ¶ŸäÿßŸã ÿ®ÿπÿØ ÿßŸÑÿ™ŸÇÿßÿ∑ ÿßŸÑÿµŸàÿ±ÿ©).
            - ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿ£ÿ≥ÿ¶ŸÑÿ©: ŸÅŸä ŸÉŸÑ ŸÖÿ±ÿ≠ŸÑÿ©ÿå ÿ≥ŸäŸèÿ±ÿ≥ŸÑ ŸÑŸÉ ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ∞Ÿä Ÿäÿ¨ÿ® ÿ£ŸÜ ÿ™ÿ≥ÿ£ŸÑŸäŸá. ÿßÿ≥ÿ£ŸÑŸä Ÿáÿ∞ÿß ÿßŸÑÿ≥ÿ§ÿßŸÑ ŸÅŸÇÿ∑ Ÿàÿ≠ÿµÿ±ŸäÿßŸãÿå ÿ´ŸÖ ÿßÿ≥ÿ™ŸÜŸä ÿ•ÿ¨ÿßÿ®ÿ© ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿµŸàÿ™Ÿäÿ©. ÿ®ÿπÿØ ÿ£ŸÜ Ÿäÿ¨ÿßŸàÿ® Ÿàÿ™ÿ±ÿØŸä ÿπŸÑŸäŸáÿå ÿßÿ≥ÿ™ÿØÿπŸä go_to_next_step ŸÅŸàÿ±ÿßŸã ŸÑŸäŸÜŸÇŸÑŸÉ ÿßŸÑŸÜÿ∏ÿßŸÖ ŸÑŸÑÿ≥ÿ§ÿßŸÑ ÿßŸÑÿ™ÿßŸÑŸä. ŸÑÿß ÿ™ÿ≥ÿ£ŸÑŸä ÿ£ŸÉÿ´ÿ± ŸÖŸÜ ÿ≥ÿ§ÿßŸÑ Ÿàÿßÿ≠ÿØ ŸÅŸä ŸÉŸÑ ŸÖÿ±ÿ©.
            - ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑŸÖŸÜÿ™ÿ¨ÿßÿ™ ŸàÿßŸÑÿ±Ÿàÿ™ŸäŸÜ: ŸÇÿØŸÖŸäŸáŸÖ ÿ®ÿ≠ŸÖÿßÿ≥. ŸÑÿß ÿ™ÿ≥ÿ™ÿØÿπŸä go_to_next_step.
            - ÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑÿÆÿ™ÿßŸÖ: ŸÇŸàŸÑŸä ÿßŸÑÿ±ÿ≥ÿßŸÑÿ© ÿßŸÑÿÆÿ™ÿßŸÖŸäÿ©. ŸÑÿß ÿ™ÿ≥ÿ™ÿØÿπŸä go_to_next_step.
            
            ÿ™ÿ∞ŸÉÿ±Ÿä: ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÑÿß Ÿäÿ±Ÿâ ÿßŸÑÿ™ÿπŸÑŸäŸÖÿßÿ™ ÿßŸÑŸÖÿÆŸÅŸäÿ©ÿå ŸÑÿ∞ÿß ÿ™ÿ≠ÿØÿ´Ÿä ŸàŸÉÿ£ŸÜŸÉŸê ÿ™ŸÇŸàÿØŸäŸÜ ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿ∑ÿ®ŸäÿπŸäÿßŸã.`
        }]
    }
};

class GeminiLiveService {
    private client: GoogleGenAI | null = null;
    private session: any = null;
    private audioContext: AudioContext | null = null;
    private mediaStream: MediaStream | null = null;
    private audioProcessor: ScriptProcessorNode | null = null;
    public isConnected: boolean = false;
    private audioQueue: ArrayBuffer[] = [];
    private currentSource: AudioBufferSourceNode | null = null;
    private playbackContext: AudioContext | null = null;
    private nextStartTime: number = 0;
    private isProcessingQueue: boolean = false;
    private onConnectionChange: ((connected: boolean) => void) | null = null;
    private onSpeakingChange: ((speaking: boolean) => void) | null = null;
    private onUserSpeech: ((isSpeech: boolean) => void) | null = null;
    private onLoadingChange: ((loading: boolean) => void) | null = null;
    private onFunctionCall: ((functionName: string, args: any) => void) | null = null;
    private silenceTimer: any = null;
    private isUserSpeaking: boolean = false;

    private purposefulDisconnect: boolean = false;
    private lastGender: 'male' | 'female' = 'female';
    private lastApiKey: string = '';

    constructor() { }

    setCallbacks(
        onConnectionChange: (connected: boolean) => void,
        onSpeakingChange: (speaking: boolean) => void,
        onUserSpeech: (isSpeech: boolean) => void,
        onLoadingChange?: (loading: boolean) => void,
        onFunctionCall?: (functionName: string, args: any) => void
    ) {
        this.onConnectionChange = onConnectionChange;
        this.onSpeakingChange = onSpeakingChange;
        this.onUserSpeech = onUserSpeech;
        this.onLoadingChange = onLoadingChange || null;
        this.onFunctionCall = onFunctionCall || null;
    }

    async connect(apiKey: string, gender: 'male' | 'female' = 'female') {
        // If already connected, skip
        if (this.isConnected) return;

        this.purposefulDisconnect = false;
        this.lastGender = gender;
        this.lastApiKey = apiKey;

        // If there's a stale session, clean it up first
        if (this.session) {
            this.stopAudioInput();
            this.session = null;
            await new Promise(r => setTimeout(r, 500));
        }

        try {
            console.log('Initializing Gemini Client with provided key...');
            this.client = new GoogleGenAI({ apiKey });

            console.log('Attempting to connect to Gemini Live (Callbacks Mode)...');

            const audioStarted = await this.startAudioInput();
            if (!audioStarted) {
                throw new Error('Microphone permission denied or audio failed to start');
            }

            const dynamicConfig = {
                ...config,
                systemInstruction: {
                    parts: [{
                        text: config.systemInstruction.parts[0].text + `\n\n=== ÿ™ŸÜÿ®ŸäŸá ŸáÿßŸÖ ===\nÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ÿßŸÑÿ≠ÿßŸÑŸä ŸáŸà: ${gender === 'male' ? 'ÿ∞ŸÉÿ±' : 'ÿ£ŸÜÿ´Ÿâ'}. Ÿäÿ¨ÿ® ÿßŸÑÿ™ÿ≠ÿØÿ´ ŸÖÿπŸá ÿ®ÿµŸäÿ∫ÿ© ÿßŸÑ${gender === 'male' ? 'ŸÖÿ∞ŸÉÿ± (ŸÖÿ´ÿßŸÑ: ÿ¨ÿßŸáÿ≤ÿü ÿµŸàÿ±ÿ™ŸÉ)' : 'ŸÖÿ§ŸÜÿ´ (ŸÖÿ´ÿßŸÑ: ÿ¨ÿßŸáÿ≤ÿ©ÿü ÿµŸàÿ±ÿ™ŸÉ)'} ÿØÿßÿ¶ŸÖÿßŸã.`
                    }]
                }
            };

            // @ts-ignore
            this.session = await this.client.live.connect({
                model: MODEL,
                config: dynamicConfig,
                callbacks: {
                    onopen: () => {
                        console.log('‚úÖ Connected to Gemini Live API');
                        this.isConnected = true;
                        this.onConnectionChange?.(true);
                    },
                    onmessage: (message: any) => {
                        this.handleServerMessage(message);
                    },
                    onerror: (e: any) => {
                        console.error('‚ùå Gemini Live Error:', e);
                    },
                    onclose: (e: any) => {
                        console.log('üîí Gemini Live Closed:', e);
                        this.isConnected = false;
                        this.stopAudioInput();
                        this.session = null;
                        this.onConnectionChange?.(false);

                        // Auto-reconnect if not a purposeful disconnect
                        if (!this.purposefulDisconnect && this.lastApiKey) {
                            console.log('üîÑ Auto-reconnecting in 2s...');
                            setTimeout(() => {
                                if (!this.isConnected && !this.purposefulDisconnect) {
                                    this.connect(this.lastApiKey, this.lastGender);
                                }
                            }, 2000);
                        }
                    }
                }
            });

        } catch (error) {
            console.error('Failed to connect to Gemini Live:', error);
            this.disconnect();
            throw error;
        }
    }

    // Removed the old connect method and merged logic into the main connect
    async connectWithCallbacks(apiKey: string, gender: 'male' | 'female' = 'female') {
        return this.connect(apiKey, gender);
    }

    // sendInitialGreeting method is removed completely

    async disconnect() {
        // Mark as purposeful disconnect to prevent auto-reconnect
        this.purposefulDisconnect = true;
        this.isConnected = false;
        this.onConnectionChange?.(false);

        // Stop audio to prevent further WebSocket sends
        this.stopAudioInput();

        // Close session
        if (this.session) {
            try {
                this.session.close();
            } catch (e) {
                // Ignore close errors
            }
            this.session = null;
        }
    }

    sendMessage(text: string) {
        if (!this.session || !this.isConnected) return;
        console.log('üì§ Sending message to model:', text);
        this.onLoadingChange?.(true);
        try {
            this.session.sendClientContent({ turns: [{ role: 'user', parts: [{ text }] }], turnComplete: true });
        } catch (error) {
            console.error('‚ùå Error sending message:', error);
            this.onLoadingChange?.(false);
        }
    }

    sendImage(base64Image: string, mimeType: string = "image/jpeg") {
        if (!this.session || !this.isConnected) return;
        console.log('üì§ Sending image to model...');
        try {
            this.session.sendRealtimeInput({
                mediaChunks: [{
                    mimeType: mimeType,
                    data: base64Image
                }]
            });
        } catch (error) {
            console.error('‚ùå Error sending image:', error);
        }
    }

    private async startAudioInput(): Promise<boolean> {
        this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
            sampleRate: 16000
        });

        try {
            this.mediaStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    sampleRate: 16000
                }
            });

            console.log(`AudioContext State: ${this.audioContext.state}`);
            if (this.audioContext.state === 'suspended') {
                console.log('üîä Resuming AudioContext...');
                await this.audioContext.resume();
                console.log(`AudioContext New State: ${this.audioContext.state}`);
            }

            const source = this.audioContext.createMediaStreamSource(this.mediaStream);

            this.audioProcessor = this.audioContext.createScriptProcessor(4096, 1, 1);

            let frameCount = 0;
            this.audioProcessor.onaudioprocess = (e) => {
                if (!this.isConnected || !this.session) return;

                const inputData = e.inputBuffer.getChannelData(0);

                // Calculate RMS for logging and VAD
                let sum = 0;
                for (let i = 0; i < inputData.length; i++) {
                    sum += inputData[i] * inputData[i];
                }
                const rms = Math.sqrt(sum / inputData.length);

                // Simple VAD (Voice Activity Detection)
                const VAD_THRESHOLD = 0.01;
                if (rms > VAD_THRESHOLD) {
                    if (!this.isUserSpeaking) {
                        this.isUserSpeaking = true;
                        this.onUserSpeech?.(true);
                    }
                    // Reset silence timer
                    if (this.silenceTimer) clearTimeout(this.silenceTimer);
                    this.silenceTimer = setTimeout(() => {
                        this.isUserSpeaking = false;
                        this.onUserSpeech?.(false);
                    }, 1000); // 1 second of silence to consider speech ended
                }

                frameCount++;
                if (frameCount % 40 === 0) { // Reduce log frequency
                    console.log(`üé§ RMS: ${rms.toFixed(4)} | Connected: ${this.isConnected}`);
                }

                const pcm16 = this.floatTo16BitPCM(inputData);
                const base64Audio = this.arrayBufferToBase64(pcm16);

                try {
                    if (this.session && this.isConnected) {
                        this.session.sendRealtimeInput({
                            audio: {
                                data: base64Audio,
                                mimeType: "audio/pcm;rate=16000"
                            }
                        });
                    }
                } catch (err) {
                    // Silently ignore - WebSocket may be closing
                }
            };

            source.connect(this.audioProcessor);
            this.audioProcessor.connect(this.audioContext.destination);
            console.log('üîä Audio Configured: Source -> Processor -> Destination');
            return true;

        } catch (error) {
            console.error('Error accessing microphone:', error);
            return false;
        }
    }

    private stopAudioInput() {
        this.mediaStream?.getTracks().forEach(track => track.stop());
        this.audioProcessor?.disconnect();
        this.audioContext?.close();
        this.currentSource?.stop();
        this.playbackContext?.close();

        this.mediaStream = null;
        this.audioProcessor = null;
        this.audioContext = null;
        this.currentSource = null;
        this.playbackContext = null;
        this.nextStartTime = 0;
    }

    private handleServerMessage(message: any) {
        // Handle interruptions
        if (message.serverContent?.interrupted) {
            this.audioQueue = [];
            this.onLoadingChange?.(false);
            if (this.currentSource) {
                this.currentSource.stop();
                this.onSpeakingChange?.(false);
            }
            this.nextStartTime = 0;
            return;
        }

        // Handle function calls (toolCall)
        if (message.toolCall) {
            console.log('üîß Received toolCall:', JSON.stringify(message.toolCall));
            const functionCalls = message.toolCall.functionCalls;
            if (functionCalls && functionCalls.length > 0) {
                const functionResponses: any[] = [];
                for (const fc of functionCalls) {
                    console.log(`üîß Function call: ${fc.name}`, fc.args);
                    this.onFunctionCall?.(fc.name, fc.args || {});
                    functionResponses.push({
                        id: fc.id,
                        name: fc.name,
                        response: { success: true }
                    });
                }
                // Send tool response back to the model
                try {
                    this.session?.sendToolResponse({ functionResponses });
                    console.log('üîß Sent toolResponse back to model');
                } catch (err) {
                    console.error('‚ùå Error sending toolResponse:', err);
                }
            }
            return;
        }

        // Handle audio content
        if (message.serverContent?.modelTurn?.parts) {
            this.onLoadingChange?.(false);
            for (const part of message.serverContent.modelTurn.parts) {
                if (part.inlineData && part.inlineData.data) {
                    const audioData = this.base64ToArrayBuffer(part.inlineData.data);
                    this.audioQueue.push(audioData);
                    this.playNextInQueue();
                }
            }
        }
    }

    private async playNextInQueue() {
        if (this.isProcessingQueue) return;
        this.isProcessingQueue = true;

        try {
            if (!this.playbackContext) {
                this.playbackContext = new (window.AudioContext || (window as any).webkitAudioContext)({
                    sampleRate: 24000,
                });
            }

            if (this.playbackContext.state === 'suspended') {
                await this.playbackContext.resume();
            }

            this.onSpeakingChange?.(true);

            while (this.audioQueue.length > 0) {
                const audioData = this.audioQueue.shift()!;
                try {
                    const audioBuffer = this.createAudioBufferFromPCM(audioData, 24000, this.playbackContext);
                    const source = this.playbackContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(this.playbackContext.destination);

                    const currentTime = this.playbackContext.currentTime;
                    const startTime = Math.max(currentTime, this.nextStartTime);

                    source.start(startTime);
                    this.nextStartTime = startTime + audioBuffer.duration;
                    this.currentSource = source;

                } catch (error) {
                    console.error('‚ùå Error playing audio:', error);
                }
            }
        } catch (error) {
            console.error('‚ùå Error in audio playback loop:', error);
        } finally {
            this.isProcessingQueue = false;
            setTimeout(() => {
                if (this.audioQueue.length === 0 && !this.isProcessingQueue) {
                    this.onSpeakingChange?.(false);
                }
            }, 500);
        }
    }

    private floatTo16BitPCM(input: Float32Array): ArrayBuffer {
        const output = new Int16Array(input.length);
        for (let i = 0; i < input.length; i++) {
            const s = Math.max(-1, Math.min(1, input[i]));
            output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        return output.buffer;
    }

    private arrayBufferToBase64(buffer: ArrayBuffer): string {
        let binary = '';
        const bytes = new Uint8Array(buffer);
        const len = bytes.byteLength;
        for (let i = 0; i < len; i++) {
            binary += String.fromCharCode(bytes[i]);
        }
        return window.btoa(binary);
    }

    private base64ToArrayBuffer(base64: string): ArrayBuffer {
        const binaryString = window.atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
    }

    private createAudioBufferFromPCM(data: ArrayBuffer, sampleRate: number, context: AudioContext): AudioBuffer {
        const int16 = new Int16Array(data);
        const float32 = new Float32Array(int16.length);

        for (let i = 0; i < int16.length; i++) {
            float32[i] = int16[i] / 32768;
        }

        const buffer = context.createBuffer(1, float32.length, sampleRate);
        buffer.getChannelData(0).set(float32);
        return buffer;
    }
}

export const geminiLive = new GeminiLiveService();
